google-bert/bert-base-uncased
./output_model
length of dataset is 26732
========================
Training Config: TrainingArguments(
_n_gpu=4,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./train_logs,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.COSINE,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=4,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=./output_model,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=16,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=./output_model,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.01,
)
Start Training...
{'loss': 1.1292, 'grad_norm': 233423.515625, 'learning_rate': 2.7e-06, 'epoch': 0.03}
{'loss': 1.0936, 'grad_norm': 116401.8203125, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.05}
{'loss': 1.0965, 'grad_norm': 134425.96875, 'learning_rate': 8.7e-06, 'epoch': 0.08}
{'loss': 1.0615, 'grad_norm': 176612.234375, 'learning_rate': 1.1700000000000001e-05, 'epoch': 0.11}
{'loss': 1.0218, 'grad_norm': 256111.6875, 'learning_rate': 1.47e-05, 'epoch': 0.13}
{'loss': 0.9412, 'grad_norm': 294510.03125, 'learning_rate': 1.77e-05, 'epoch': 0.16}
{'loss': 0.8465, 'grad_norm': 266642.25, 'learning_rate': 2.07e-05, 'epoch': 0.19}
{'loss': 0.7326, 'grad_norm': 269644.28125, 'learning_rate': 2.37e-05, 'epoch': 0.21}
{'loss': 0.6934, 'grad_norm': 364876.71875, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.24}
{'loss': 0.6631, 'grad_norm': 537790.75, 'learning_rate': 2.97e-05, 'epoch': 0.27}
{'loss': 0.6287, 'grad_norm': 237878.265625, 'learning_rate': 2.9996958434772755e-05, 'epoch': 0.29}
{'loss': 0.5591, 'grad_norm': 331381.28125, 'learning_rate': 2.9986445965730904e-05, 'epoch': 0.32}
{'loss': 0.5956, 'grad_norm': 276154.59375, 'learning_rate': 2.9968430304660503e-05, 'epoch': 0.35}
{'loss': 0.6047, 'grad_norm': 253832.546875, 'learning_rate': 2.9942920471376185e-05, 'epoch': 0.37}
{'loss': 0.6044, 'grad_norm': 308002.21875, 'learning_rate': 2.990992923776383e-05, 'epoch': 0.4}
{'loss': 0.5424, 'grad_norm': 230760.625, 'learning_rate': 2.9869473121386152e-05, 'epoch': 0.43}
{'loss': 0.5885, 'grad_norm': 280205.28125, 'learning_rate': 2.982157237721292e-05, 'epoch': 0.45}
{'loss': 0.5807, 'grad_norm': 197585.296875, 'learning_rate': 2.9766250987479985e-05, 'epoch': 0.48}
{'loss': 0.5731, 'grad_norm': 230835.203125, 'learning_rate': 2.970353664968224e-05, 'epoch': 0.51}
{'loss': 0.5945, 'grad_norm': 331822.09375, 'learning_rate': 2.963346076270641e-05, 'epoch': 0.53}
{'loss': 0.6036, 'grad_norm': 221384.59375, 'learning_rate': 2.955605841111076e-05, 'epoch': 0.56}
{'loss': 0.5433, 'grad_norm': 227363.75, 'learning_rate': 2.947136834755944e-05, 'epoch': 0.59}
{'loss': 0.5551, 'grad_norm': 241435.265625, 'learning_rate': 2.937943297342042e-05, 'epoch': 0.61}
{'loss': 0.5505, 'grad_norm': 230762.625, 'learning_rate': 2.9280298317536554e-05, 'epoch': 0.64}
{'loss': 0.5713, 'grad_norm': 335346.21875, 'learning_rate': 2.917401401318056e-05, 'epoch': 0.66}
{'loss': 0.5161, 'grad_norm': 284160.15625, 'learning_rate': 2.906063327320538e-05, 'epoch': 0.69}
{'loss': 0.574, 'grad_norm': 289603.21875, 'learning_rate': 2.8940212863402334e-05, 'epoch': 0.72}
{'loss': 0.5259, 'grad_norm': 234861.5625, 'learning_rate': 2.8812813074080484e-05, 'epoch': 0.74}
{'loss': 0.5475, 'grad_norm': 294442.125, 'learning_rate': 2.8678497689881354e-05, 'epoch': 0.77}
{'loss': 0.5782, 'grad_norm': 268131.125, 'learning_rate': 2.8537333957844185e-05, 'epoch': 0.8}
{'loss': 0.5402, 'grad_norm': 176519.65625, 'learning_rate': 2.8389392553737694e-05, 'epoch': 0.82}
{'loss': 0.5248, 'grad_norm': 241733.1875, 'learning_rate': 2.823474754667517e-05, 'epoch': 0.85}
{'loss': 0.4694, 'grad_norm': 266643.53125, 'learning_rate': 2.8073476362030643e-05, 'epoch': 0.88}
{'loss': 0.5787, 'grad_norm': 199461.109375, 'learning_rate': 2.7905659742674687e-05, 'epoch': 0.9}
{'loss': 0.5157, 'grad_norm': 438496.9375, 'learning_rate': 2.773138170854929e-05, 'epoch': 0.93}
{'loss': 0.5758, 'grad_norm': 262018.4375, 'learning_rate': 2.7550729514601982e-05, 'epoch': 0.96}
{'loss': 0.5562, 'grad_norm': 168737.015625, 'learning_rate': 2.736379360710032e-05, 'epoch': 0.98}
{'eval_loss': 0.5298880934715271, 'eval_accuracy': 0.7807706696595585, 'eval_runtime': 3.1616, 'eval_samples_per_second': 845.455, 'eval_steps_per_second': 13.284, 'epoch': 1.0}
{'loss': 0.5209, 'grad_norm': 252711.15625, 'learning_rate': 2.7170667578348598e-05, 'epoch': 1.01}
{'loss': 0.4813, 'grad_norm': 251171.453125, 'learning_rate': 2.697144811982941e-05, 'epoch': 1.04}
{'loss': 0.3978, 'grad_norm': 251515.625, 'learning_rate': 2.6766234973793638e-05, 'epoch': 1.06}
{'loss': 0.4268, 'grad_norm': 180580.765625, 'learning_rate': 2.655513088332292e-05, 'epoch': 1.09}
{'loss': 0.3752, 'grad_norm': 246655.15625, 'learning_rate': 2.63382415408898e-05, 'epoch': 1.12}
{'loss': 0.4313, 'grad_norm': 326020.9375, 'learning_rate': 2.611567553544119e-05, 'epoch': 1.14}
{'loss': 0.4171, 'grad_norm': 269201.46875, 'learning_rate': 2.5887544298031635e-05, 'epoch': 1.17}
{'loss': 0.3681, 'grad_norm': 295361.15625, 'learning_rate': 2.5653962046033684e-05, 'epoch': 1.2}
{'loss': 0.4664, 'grad_norm': 261223.71875, 'learning_rate': 2.5415045725953202e-05, 'epoch': 1.22}
{'loss': 0.3934, 'grad_norm': 322922.5, 'learning_rate': 2.5170914954878366e-05, 'epoch': 1.25}
{'loss': 0.47, 'grad_norm': 303620.75, 'learning_rate': 2.49216919605915e-05, 'epoch': 1.28}
{'loss': 0.4361, 'grad_norm': 281576.59375, 'learning_rate': 2.4667501520373912e-05, 'epoch': 1.3}
{'loss': 0.4583, 'grad_norm': 248941.234375, 'learning_rate': 2.4408470898534244e-05, 'epoch': 1.33}
{'loss': 0.4555, 'grad_norm': 235845.96875, 'learning_rate': 2.414472978269165e-05, 'epoch': 1.36}
{'loss': 0.4544, 'grad_norm': 177936.25, 'learning_rate': 2.3876410218845732e-05, 'epoch': 1.38}
{'loss': 0.4384, 'grad_norm': 204847.28125, 'learning_rate': 2.360364654526569e-05, 'epoch': 1.41}
{'loss': 0.445, 'grad_norm': 301911.96875, 'learning_rate': 2.3326575325231845e-05, 'epoch': 1.44}
{'loss': 0.3747, 'grad_norm': 317598.78125, 'learning_rate': 2.3045335278663127e-05, 'epoch': 1.46}
{'loss': 0.3919, 'grad_norm': 254996.796875, 'learning_rate': 2.2760067212664852e-05, 'epoch': 1.49}
{'loss': 0.4291, 'grad_norm': 257760.765625, 'learning_rate': 2.2470913951031525e-05, 'epoch': 1.52}
{'loss': 0.4833, 'grad_norm': 269688.34375, 'learning_rate': 2.2178020262739898e-05, 'epoch': 1.54}
{'loss': 0.403, 'grad_norm': 187005.4375, 'learning_rate': 2.1881532789468213e-05, 'epoch': 1.57}
{'loss': 0.4142, 'grad_norm': 219435.9375, 'learning_rate': 2.1581599972177787e-05, 'epoch': 1.6}
{'loss': 0.4206, 'grad_norm': 249634.796875, 'learning_rate': 2.1278371976793818e-05, 'epoch': 1.62}
{'loss': 0.4184, 'grad_norm': 249867.96875, 'learning_rate': 2.0972000619022515e-05, 'epoch': 1.65}
{'loss': 0.406, 'grad_norm': 243184.625, 'learning_rate': 2.0662639288342254e-05, 'epoch': 1.68}
{'loss': 0.3898, 'grad_norm': 280096.9375, 'learning_rate': 2.0350442871206802e-05, 'epoch': 1.7}
{'loss': 0.4214, 'grad_norm': 231947.09375, 'learning_rate': 2.0035567673499073e-05, 'epoch': 1.73}
{'loss': 0.4378, 'grad_norm': 180117.71875, 'learning_rate': 1.9718171342274207e-05, 'epoch': 1.76}
{'loss': 0.37, 'grad_norm': 326080.21875, 'learning_rate': 1.939841278683116e-05, 'epoch': 1.78}
{'loss': 0.4231, 'grad_norm': 256672.5, 'learning_rate': 1.9076452099152367e-05, 'epoch': 1.81}
{'loss': 0.4023, 'grad_norm': 308722.1875, 'learning_rate': 1.875245047375124e-05, 'epoch': 1.84}
{'loss': 0.4337, 'grad_norm': 210967.90625, 'learning_rate': 1.8426570126967707e-05, 'epoch': 1.86}
{'loss': 0.4452, 'grad_norm': 309813.40625, 'learning_rate': 1.8098974215752105e-05, 'epoch': 1.89}
{'loss': 0.4103, 'grad_norm': 453175.09375, 'learning_rate': 1.776982675597819e-05, 'epoch': 1.91}
{'loss': 0.4511, 'grad_norm': 278040.78125, 'learning_rate': 1.7439292540326104e-05, 'epoch': 1.94}
{'loss': 0.3912, 'grad_norm': 309480.03125, 'learning_rate': 1.710753705577639e-05, 'epoch': 1.97}
{'loss': 0.4591, 'grad_norm': 264446.125, 'learning_rate': 1.6774726400756446e-05, 'epoch': 1.99}
{'eval_loss': 0.5235012769699097, 'eval_accuracy': 0.7938645716423495, 'eval_runtime': 3.1351, 'eval_samples_per_second': 852.608, 'eval_steps_per_second': 13.397, 'epoch': 2.0}
{'loss': 0.3382, 'grad_norm': 250205.15625, 'learning_rate': 1.64410272019808e-05, 'epoch': 2.02}
{'loss': 0.3069, 'grad_norm': 303597.28125, 'learning_rate': 1.6106606531026926e-05, 'epoch': 2.05}
{'loss': 0.249, 'grad_norm': 239203.34375, 'learning_rate': 1.5771631820688306e-05, 'epoch': 2.07}
{'loss': 0.2274, 'grad_norm': 289262.1875, 'learning_rate': 1.543627078114667e-05, 'epoch': 2.1}
{'loss': 0.3237, 'grad_norm': 384515.5, 'learning_rate': 1.5100691316005344e-05, 'epoch': 2.13}
{'loss': 0.2903, 'grad_norm': 238410.96875, 'learning_rate': 1.4765061438225731e-05, 'epoch': 2.15}
{'loss': 0.305, 'grad_norm': 258692.4375, 'learning_rate': 1.4429549186009106e-05, 'epoch': 2.18}
{'loss': 0.2606, 'grad_norm': 210087.71875, 'learning_rate': 1.4094322538665707e-05, 'epoch': 2.21}
{'loss': 0.3125, 'grad_norm': 238325.609375, 'learning_rate': 1.3759549332513366e-05, 'epoch': 2.23}
{'loss': 0.2812, 'grad_norm': 247903.703125, 'learning_rate': 1.3425397176847668e-05, 'epoch': 2.26}
{'loss': 0.2537, 'grad_norm': 253981.03125, 'learning_rate': 1.3092033370025841e-05, 'epoch': 2.29}
{'loss': 0.2915, 'grad_norm': 325530.78125, 'learning_rate': 1.2759624815706274e-05, 'epoch': 2.31}
{'loss': 0.2918, 'grad_norm': 344131.4375, 'learning_rate': 1.242833793928567e-05, 'epoch': 2.34}
{'loss': 0.3043, 'grad_norm': 511792.8125, 'learning_rate': 1.2098338604575632e-05, 'epoch': 2.37}
{'loss': 0.3077, 'grad_norm': 316461.1875, 'learning_rate': 1.1769792030760435e-05, 'epoch': 2.39}
{'loss': 0.3123, 'grad_norm': 225016.875, 'learning_rate': 1.1442862709677535e-05, 'epoch': 2.42}
{'loss': 0.2884, 'grad_norm': 210384.65625, 'learning_rate': 1.1117714323462188e-05, 'epoch': 2.45}
{'loss': 0.3096, 'grad_norm': 305137.8125, 'learning_rate': 1.0794509662597563e-05, 'epoch': 2.47}
{'loss': 0.314, 'grad_norm': 319228.0, 'learning_rate': 1.047341054441116e-05, 'epoch': 2.5}
{'loss': 0.2555, 'grad_norm': 290918.21875, 'learning_rate': 1.0154577732058534e-05, 'epoch': 2.53}
{'loss': 0.2682, 'grad_norm': 254757.40625, 'learning_rate': 9.838170854034758e-06, 'epoch': 2.55}
{'loss': 0.2644, 'grad_norm': 233790.28125, 'learning_rate': 9.524348324254013e-06, 'epoch': 2.58}
{'loss': 0.2745, 'grad_norm': 262912.15625, 'learning_rate': 9.213267262737223e-06, 'epoch': 2.61}
{'loss': 0.2515, 'grad_norm': 213130.609375, 'learning_rate': 8.905083416947549e-06, 'epoch': 2.63}
{'loss': 0.2597, 'grad_norm': 319019.15625, 'learning_rate': 8.599951083813068e-06, 'epoch': 2.66}
{'loss': 0.3012, 'grad_norm': 326966.625, 'learning_rate': 8.298023032475613e-06, 'epoch': 2.69}
{'loss': 0.2498, 'grad_norm': 383329.9375, 'learning_rate': 7.999450427804654e-06, 'epoch': 2.71}
{'loss': 0.2899, 'grad_norm': 399034.65625, 'learning_rate': 7.704382754714245e-06, 'epoch': 2.74}
{'loss': 0.2999, 'grad_norm': 376248.40625, 'learning_rate': 7.412967743321178e-06, 'epoch': 2.77}
{'loss': 0.3557, 'grad_norm': 328625.4375, 'learning_rate': 7.1253512949815995e-06, 'epoch': 2.79}
{'loss': 0.2802, 'grad_norm': 514635.25, 'learning_rate': 6.841677409243334e-06, 'epoch': 2.82}
{'loss': 0.2896, 'grad_norm': 279228.8125, 'learning_rate': 6.5620881117502975e-06, 'epoch': 2.85}
{'loss': 0.2751, 'grad_norm': 360710.84375, 'learning_rate': 6.286723383135185e-06, 'epoch': 2.87}
{'loss': 0.286, 'grad_norm': 310497.9375, 'learning_rate': 6.015721088936058e-06, 'epoch': 2.9}
{'loss': 0.275, 'grad_norm': 260794.078125, 'learning_rate': 5.749216910571854e-06, 'epoch': 2.93}
{'loss': 0.2779, 'grad_norm': 502634.34375, 'learning_rate': 5.487344277411445e-06, 'epoch': 2.95}
{'loss': 0.3172, 'grad_norm': 237852.046875, 'learning_rate': 5.2302342999701555e-06, 'epoch': 2.98}
{'eval_loss': 0.5942386388778687, 'eval_accuracy': 0.7860082304526749, 'eval_runtime': 3.2927, 'eval_samples_per_second': 811.787, 'eval_steps_per_second': 12.755, 'epoch': 3.0}
{'loss': 0.2763, 'grad_norm': 162941.15625, 'learning_rate': 4.978015704267341e-06, 'epoch': 3.01}
{'loss': 0.2107, 'grad_norm': 239167.21875, 'learning_rate': 4.730814767377683e-06, 'epoch': 3.03}
{'loss': 0.1906, 'grad_norm': 301768.5, 'learning_rate': 4.48875525420872e-06, 'epoch': 3.06}
{'loss': 0.1863, 'grad_norm': 244668.84375, 'learning_rate': 4.251958355536024e-06, 'epoch': 3.09}
{'loss': 0.2195, 'grad_norm': 253384.359375, 'learning_rate': 4.020542627327205e-06, 'epoch': 3.11}
{'loss': 0.2014, 'grad_norm': 243771.78125, 'learning_rate': 3.7946239313850626e-06, 'epoch': 3.14}
{'loss': 0.1864, 'grad_norm': 495304.03125, 'learning_rate': 3.574315377339613e-06, 'epoch': 3.16}
{'loss': 0.2536, 'grad_norm': 360419.0, 'learning_rate': 3.3597272660180463e-06, 'epoch': 3.19}
{'loss': 0.2252, 'grad_norm': 222356.625, 'learning_rate': 3.1509670342209096e-06, 'epoch': 3.22}
{'loss': 0.1975, 'grad_norm': 221928.828125, 'learning_rate': 2.948139200932281e-06, 'epoch': 3.24}
{'loss': 0.163, 'grad_norm': 193109.8125, 'learning_rate': 2.7513453149907084e-06, 'epoch': 3.27}
{'loss': 0.2193, 'grad_norm': 334208.5, 'learning_rate': 2.5606839042472667e-06, 'epoch': 3.3}
{'loss': 0.2034, 'grad_norm': 250394.140625, 'learning_rate': 2.3762504262360913e-06, 'epoch': 3.32}
{'loss': 0.1715, 'grad_norm': 276299.46875, 'learning_rate': 2.1981372203820933e-06, 'epoch': 3.35}
{'loss': 0.1924, 'grad_norm': 239871.453125, 'learning_rate': 2.0264334617698394e-06, 'epoch': 3.38}
{'loss': 0.2158, 'grad_norm': 455120.8125, 'learning_rate': 1.861225116496682e-06, 'epoch': 3.4}
{'loss': 0.1982, 'grad_norm': 183061.25, 'learning_rate': 1.7025948986325379e-06, 'epoch': 3.43}
{'loss': 0.2168, 'grad_norm': 488773.96875, 'learning_rate': 1.5506222288078043e-06, 'epoch': 3.46}
{'loss': 0.1713, 'grad_norm': 373412.46875, 'learning_rate': 1.4053831944502509e-06, 'epoch': 3.48}
{'loss': 0.1951, 'grad_norm': 398836.40625, 'learning_rate': 1.2669505116906565e-06, 'epoch': 3.51}
{'loss': 0.2277, 'grad_norm': 285441.3125, 'learning_rate': 1.13539348895639e-06, 'epoch': 3.54}
{'loss': 0.1486, 'grad_norm': 334309.96875, 'learning_rate': 1.0107779922710964e-06, 'epoch': 3.56}
{'loss': 0.2251, 'grad_norm': 365075.625, 'learning_rate': 8.93166412277861e-07, 'epoch': 3.59}
{'loss': 0.2224, 'grad_norm': 276532.5, 'learning_rate': 7.826176330023876e-07, 'epoch': 3.62}
{'loss': 0.215, 'grad_norm': 288510.46875, 'learning_rate': 6.791870023718161e-07, 'epoch': 3.64}
{'loss': 0.2076, 'grad_norm': 161446.875, 'learning_rate': 5.829263045039468e-07, 'epoch': 3.67}
{'loss': 0.1835, 'grad_norm': 230467.25, 'learning_rate': 4.93883733780725e-07, 'epoch': 3.7}
{'loss': 0.1954, 'grad_norm': 297150.5, 'learning_rate': 4.121038707190006e-07, 'epoch': 3.72}
{'loss': 0.2392, 'grad_norm': 370372.96875, 'learning_rate': 3.3762765965060507e-07, 'epoch': 3.75}
{'loss': 0.1872, 'grad_norm': 211139.03125, 'learning_rate': 2.7049238822295317e-07, 'epoch': 3.78}
{'loss': 0.232, 'grad_norm': 296610.6875, 'learning_rate': 2.1073166873042115e-07, 'epoch': 3.8}
{'loss': 0.1681, 'grad_norm': 106702.125, 'learning_rate': 1.5837542128583294e-07, 'epoch': 3.83}
{'loss': 0.1593, 'grad_norm': 285158.125, 'learning_rate': 1.1344985884049974e-07, 'epoch': 3.86}
{'loss': 0.2112, 'grad_norm': 311881.65625, 'learning_rate': 7.597747406031641e-08, 'epoch': 3.88}
{'loss': 0.2044, 'grad_norm': 266083.875, 'learning_rate': 4.5977028064454474e-08, 'epoch': 3.91}
{'loss': 0.2276, 'grad_norm': 259024.671875, 'learning_rate': 2.3463541032337498e-08, 'epoch': 3.94}
{'loss': 0.1875, 'grad_norm': 171948.4375, 'learning_rate': 8.44828468354153e-09, 'epoch': 3.96}
{'loss': 0.1848, 'grad_norm': 169630.75, 'learning_rate': 9.387766344542969e-10, 'epoch': 3.99}
{'eval_loss': 0.6793712377548218, 'eval_accuracy': 0.7863823419378975, 'eval_runtime': 3.1319, 'eval_samples_per_second': 853.487, 'eval_steps_per_second': 13.411, 'epoch': 4.0}
{'train_runtime': 307.1886, 'train_samples_per_second': 313.28, 'train_steps_per_second': 4.896, 'train_loss': 0.3931832421333232, 'epoch': 4.0}

Saved checkpoints in output directory:
  checkpoint-376
  checkpoint-752
  checkpoint-1128
  checkpoint-1504
  checkpoint-3008
  checkpoint-4512
  checkpoint-6016
